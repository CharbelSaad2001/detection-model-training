{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLO 12 Model Training with Data Augmentation\n",
        "\n",
        "This notebook trains a YOLO 12 model on the animal detection dataset with data augmentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n",
            "Device: cpu\n",
            "Dataset path: c:\\Users\\CHARBEL\\Desktop\\modelo-animales\\dataset\n",
            "Data YAML: c:\\Users\\CHARBEL\\Desktop\\modelo-animales\\dataset\\data.yaml\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import torch\n",
        "\n",
        "# Set up paths\n",
        "dataset_path = Path(\"dataset\")\n",
        "data_yaml = dataset_path / \"data.yaml\"\n",
        "\n",
        "# Check device availability\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Device: {device}\")\n",
        "if device == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"Dataset path: {dataset_path.absolute()}\")\n",
        "print(f\"Data YAML: {data_yaml.absolute()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Verify Dataset Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Configuration:\n",
            "Number of classes: 9\n",
            "Class names: ['Cat', 'Dog', 'Pig', 'bird', 'cow', 'duck', 'hen', 'horse', 'sheep']\n",
            "Train path: train/images\n",
            "Validation path: valid/images\n",
            "Test path: test/images\n",
            "\n",
            "Path verification:\n",
            "Train images exist: True\n",
            "Validation images exist: True\n",
            "Test images exist: True\n"
          ]
        }
      ],
      "source": [
        "# Verify data.yaml configuration\n",
        "with open(data_yaml, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "    \n",
        "print(\"Dataset Configuration:\")\n",
        "print(f\"Number of classes: {config['nc']}\")\n",
        "print(f\"Class names: {config['names']}\")\n",
        "print(f\"Train path: {config['train']}\")\n",
        "print(f\"Validation path: {config['val']}\")\n",
        "print(f\"Test path: {config['test']}\")\n",
        "\n",
        "# Verify paths exist\n",
        "train_path = dataset_path / config['train']\n",
        "val_path = dataset_path / config['val']\n",
        "test_path = dataset_path / config['test']\n",
        "\n",
        "print(f\"\\nPath verification:\")\n",
        "print(f\"Train images exist: {train_path.exists()}\")\n",
        "print(f\"Validation images exist: {val_path.exists()}\")\n",
        "print(f\"Test images exist: {test_path.exists()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Initialize YOLO 12 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING Download failure, retrying 1/3 https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo12n.pt... <urlopen error [WinError 10054] Se ha forzado la interrupcin de una conexin existente por el host remoto>\n",
            "YOLO 12 model initialized!\n",
            "Model type: detect\n"
          ]
        }
      ],
      "source": [
        "# Initialize YOLO 12 model\n",
        "# Using yolov12n (nano) for faster training, can be changed to yolov12s, yolov12m, yolov12l, yolov12x\n",
        "model = YOLO('yolo12n.pt')  # Downloads pretrained weights automatically\n",
        "\n",
        "print(\"YOLO 12 model initialized!\")\n",
        "print(f\"Model type: {model.task}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Configure Data Augmentation\n",
        "\n",
        "Data augmentation helps improve model generalization by creating variations of training images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Augmentation Configuration:\n",
            "  hsv_h: 0.015\n",
            "  hsv_s: 0.7\n",
            "  hsv_v: 0.4\n",
            "  degrees: 10.0\n",
            "  translate: 0.1\n",
            "  scale: 0.5\n",
            "  shear: 2.0\n",
            "  perspective: 0.0\n",
            "  flipud: 0.0\n",
            "  fliplr: 0.5\n",
            "  mosaic: 1.0\n",
            "  mixup: 0.1\n",
            "  copy_paste: 0.1\n"
          ]
        }
      ],
      "source": [
        "# Configure data augmentation parameters\n",
        "# These augmentations will be applied during training\n",
        "augmentation_config = {\n",
        "    'hsv_h': 0.015,      # Hue augmentation (0-1)\n",
        "    'hsv_s': 0.7,        # Saturation augmentation (0-1)\n",
        "    'hsv_v': 0.4,        # Value augmentation (0-1)\n",
        "    'degrees': 10.0,     # Rotation degrees\n",
        "    'translate': 0.1,    # Translation (fraction of image size)\n",
        "    'scale': 0.5,        # Scale augmentation (0-1)\n",
        "    'shear': 2.0,        # Shear degrees\n",
        "    'perspective': 0.0,  # Perspective augmentation (0-0.001)\n",
        "    'flipud': 0.0,       # Vertical flip probability (0-1)\n",
        "    'fliplr': 0.5,       # Horizontal flip probability (0-1)\n",
        "    'mosaic': 1.0,       # Mosaic augmentation probability (0-1)\n",
        "    'mixup': 0.1,        # Mixup augmentation probability (0-1)\n",
        "    'copy_paste': 0.1,   # Copy-paste augmentation probability (0-1)\n",
        "}\n",
        "\n",
        "print(\"Data Augmentation Configuration:\")\n",
        "for key, value in augmentation_config.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Train the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.4.7  Python-3.10.11 torch-2.9.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=c:\\Users\\CHARBEL\\Desktop\\modelo-animales\\dataset\\data.yaml, degrees=10.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolo12n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolo12_animal_detection, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=2.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=9\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  2    180864  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
            "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
            " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
            " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
            " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 21        [14, 17, 20]  1    432427  ultralytics.nn.modules.head.Detect           [9, 16, None, [64, 128, 256]] \n",
            "YOLOv12n summary: 272 layers, 2,569,803 parameters, 2,569,787 gradients, 6.5 GFLOPs\n",
            "\n",
            "Transferred 640/691 items from pretrained weights\n",
            "Freezing layer 'model.21.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.0 ms, read: 1.30.5 MB/s, size: 18.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\CHARBEL\\Desktop\\modelo-animales\\dataset\\train\\labels... 149 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 149/149 385.3it/s 0.4s0.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\CHARBEL\\Desktop\\modelo-animales\\dataset\\train\\labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.0 ms, read: 1.10.5 MB/s, size: 15.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\CHARBEL\\Desktop\\modelo-animales\\dataset\\valid\\labels... 12 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 12/12 465.9it/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\CHARBEL\\Desktop\\modelo-animales\\dataset\\valid\\labels.cache\n",
            "Plotting labels to C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mC:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100         0G      0.896        3.8     0.9544          5        640: 100% ━━━━━━━━━━━━ 10/10 7.6s/it 1:16.1sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2s/it 2.2s\n",
            "                   all         12         21   3.09e-05      0.111    0.00257    0.00154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100         0G      1.141      3.071      1.054         25        640: 100% ━━━━━━━━━━━━ 10/10 7.4s/it 1:14.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2s/it 3.2s\n",
            "                   all         12         21          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100         0G      1.102      2.724      1.029         21        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.6sss\n",
            "WARNING NMS time limit 2.600s exceeded\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.1s/it 5.1s\n",
            "                   all         12         21          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100         0G      1.085      2.482      1.019          9        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.6sss\n",
            "WARNING NMS time limit 2.600s exceeded\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.1s/it 5.1s\n",
            "                   all         12         21          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100         0G      1.083      2.266      1.018         25        640: 100% ━━━━━━━━━━━━ 10/10 7.5s/it 1:15.9sss\n",
            "WARNING NMS time limit 2.600s exceeded\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9s/it 4.9s\n",
            "                   all         12         21          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100         0G      1.093      2.198      1.045         11        640: 100% ━━━━━━━━━━━━ 10/10 7.5s/it 1:15.9sss\n",
            "WARNING NMS time limit 2.600s exceeded\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.4s/it 5.4s\n",
            "                   all         12         21          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100         0G      1.154      2.221       1.04         18        640: 100% ━━━━━━━━━━━━ 10/10 7.4s/it 1:14.8sss\n",
            "WARNING NMS time limit 2.600s exceeded\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0s/it 5.0s\n",
            "                   all         12         21          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100         0G      1.037      2.093      1.026         15        640: 100% ━━━━━━━━━━━━ 10/10 7.5s/it 1:15.0sss\n",
            "WARNING NMS time limit 2.600s exceeded\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0s/it 5.0s\n",
            "                   all         12         21          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100         0G      1.003      2.098      1.013          5        640: 100% ━━━━━━━━━━━━ 10/10 7.4s/it 1:14.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6s/it 3.6s\n",
            "                   all         12         21          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100         0G      1.001      1.917     0.9974         23        640: 100% ━━━━━━━━━━━━ 10/10 7.7s/it 1:17.1sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8s/it 3.8s\n",
            "                   all         12         21          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100         0G      1.089      1.966      1.047         14        640: 100% ━━━━━━━━━━━━ 10/10 8.6s/it 1:26.8ssss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9s/it 2.9s\n",
            "                   all         12         21   8.93e-05      0.111   9.48e-05    1.9e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100         0G      1.028      2.083      1.044         11        640: 100% ━━━━━━━━━━━━ 10/10 8.7s/it 1:27.9s1ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0s/it 3.0s\n",
            "                   all         12         21      0.422      0.472      0.332      0.219\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100         0G      1.054      1.879      1.025         10        640: 100% ━━━━━━━━━━━━ 10/10 7.6s/it 1:16.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1s/it 3.1s\n",
            "                   all         12         21      0.117      0.639      0.357      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100         0G     0.9669      1.729      1.002         14        640: 100% ━━━━━━━━━━━━ 10/10 7.3s/it 1:13.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4s/it 2.4s\n",
            "                   all         12         21      0.436      0.554      0.518      0.351\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100         0G       1.01      1.743      1.002          9        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1s/it 2.1s\n",
            "                   all         12         21      0.426      0.556      0.451      0.342\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100         0G      1.017      1.723      1.041         29        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2s/it 2.2s\n",
            "                   all         12         21      0.215      0.755      0.444      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100         0G     0.9617      1.672     0.9964         17        640: 100% ━━━━━━━━━━━━ 10/10 7.5s/it 1:15.9sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
            "                   all         12         21      0.222      0.139      0.143       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100         0G      0.943      1.572     0.9852         37        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5s/it 2.5s\n",
            "                   all         12         21      0.111      0.111     0.0276     0.0221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100         0G      0.877      1.492      0.954         19        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
            "                   all         12         21   7.27e-05      0.111     0.0298     0.0203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100         0G     0.8818      1.576     0.9772          9        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2s/it 2.2s\n",
            "                   all         12         21      0.247      0.641      0.523      0.408\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100         0G     0.8597      1.537     0.9524         17        640: 100% ━━━━━━━━━━━━ 10/10 7.3s/it 1:13.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1s/it 2.1s\n",
            "                   all         12         21      0.313      0.606      0.337      0.252\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/100         0G     0.8727      1.436     0.9569         25        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.9sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1s/it 2.1s\n",
            "                   all         12         21      0.463      0.639      0.567      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/100         0G     0.7959      1.411     0.9624         30        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.429      0.472      0.488      0.305\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/100         0G     0.8129      1.468     0.9597          9        640: 100% ━━━━━━━━━━━━ 10/10 7.0s/it 1:10.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.489       0.63      0.683       0.58\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/100         0G      0.798      1.365     0.9525         25        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.8ssss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2s/it 2.2s\n",
            "                   all         12         21      0.544      0.561       0.72      0.554\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/100         0G     0.8095      1.388     0.9366         19        640: 100% ━━━━━━━━━━━━ 10/10 7.3s/it 1:13.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.293       0.74      0.645      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/100         0G     0.8288      1.361     0.9526         27        640: 100% ━━━━━━━━━━━━ 10/10 7.3s/it 1:13.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5s/it 2.5s\n",
            "                   all         12         21      0.366      0.602      0.613      0.528\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/100         0G     0.7868      1.262     0.9339         24        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.656      0.472       0.66      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/100         0G     0.7403      1.242     0.9224         23        640: 100% ━━━━━━━━━━━━ 10/10 7.5s/it 1:15.1sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1s/it 2.1s\n",
            "                   all         12         21      0.596      0.624      0.758      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/100         0G     0.7126      1.162     0.9133         17        640: 100% ━━━━━━━━━━━━ 10/10 7.3s/it 1:13.3sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5s/it 2.5s\n",
            "                   all         12         21      0.863      0.306      0.471      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/100         0G     0.7068      1.161     0.9177          7        640: 100% ━━━━━━━━━━━━ 10/10 7.3s/it 1:13.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.839      0.333      0.578      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/100         0G     0.6923      1.177     0.9092         19        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.419      0.278      0.381      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/100         0G     0.7071      1.107      0.919          7        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.524      0.417        0.5      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/100         0G     0.7329      1.122     0.9302         14        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.582      0.475      0.406      0.305\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/100         0G      0.703      1.102     0.9127         18        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21       0.53      0.722      0.759      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/100         0G     0.7077      1.137      0.924         18        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.674      0.812      0.871       0.72\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/100         0G     0.7175       1.05     0.9175         23        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.518      0.799      0.851      0.747\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/100         0G     0.7186      1.171     0.9291         14        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.915      0.674      0.928      0.808\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/100         0G     0.7068      1.049     0.9104         23        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.798      0.854      0.976      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/100         0G     0.6807       1.01     0.9221          3        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.1sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.421      0.915      0.809        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/100         0G     0.6756     0.9397     0.8974         22        640: 100% ━━━━━━━━━━━━ 10/10 7.5s/it 1:15.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.722      0.716       0.92      0.774\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/100         0G     0.7007      1.082     0.8984         15        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.743      0.617      0.782       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/100         0G     0.6693     0.9629      0.894         12        640: 100% ━━━━━━━━━━━━ 10/10 7.0s/it 1:10.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.885       0.65      0.879       0.75\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/100         0G     0.6652     0.9479     0.9222         34        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.7ssss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21       0.73      0.804      0.921      0.781\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/100         0G     0.6778     0.9131     0.8977         10        640: 100% ━━━━━━━━━━━━ 10/10 7.0s/it 1:10.5ssss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.663      0.798      0.867      0.754\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/100         0G     0.7063     0.9757     0.9206         29        640: 100% ━━━━━━━━━━━━ 10/10 7.0s/it 1:10.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.865      0.859      0.963      0.877\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/100         0G     0.5981     0.7884     0.8857          7        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.923      0.775      0.952      0.852\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/100         0G     0.6871     0.9025     0.9208         13        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.948      0.848      0.972      0.883\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/100         0G     0.6665     0.8332     0.8884         15        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.763      0.898      0.918       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/100         0G     0.6386     0.8412     0.8864         17        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.785      0.858      0.941      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/100         0G     0.6274     0.8188     0.8932         55        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.765      0.819      0.915      0.801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/100         0G     0.5978     0.8052     0.8755          9        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.9sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.806      0.841      0.962      0.857\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/100         0G     0.6092      0.779     0.8843         17        640: 100% ━━━━━━━━━━━━ 10/10 7.3s/it 1:13.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.869       0.89      0.967      0.858\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/100         0G     0.6071     0.8106     0.8809         19        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.765      0.759      0.893      0.792\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/100         0G     0.6091     0.7435     0.8899         39        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.712      0.905      0.958      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/100         0G     0.6031     0.7746     0.8723         24        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.7ssss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.753      0.884      0.965      0.873\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/100         0G      0.594     0.7089     0.8731         26        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1s/it 2.1s\n",
            "                   all         12         21      0.699      0.949      0.953      0.857\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/100         0G       0.57     0.7316     0.8754         21        640: 100% ━━━━━━━━━━━━ 10/10 7.3s/it 1:13.9sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.709      0.929      0.964      0.885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/100         0G     0.5969     0.7461     0.8764         12        640: 100% ━━━━━━━━━━━━ 10/10 7.3s/it 1:13.3sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2s/it 2.2s\n",
            "                   all         12         21        0.8      0.906      0.899      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/100         0G     0.5841     0.7129     0.8601         30        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.647      0.884      0.958      0.843\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/100         0G     0.5793     0.6877     0.8808         19        640: 100% ━━━━━━━━━━━━ 10/10 7.0s/it 1:10.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.844      0.869      0.949      0.837\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/100         0G     0.5746     0.7026     0.8724         15        640: 100% ━━━━━━━━━━━━ 10/10 7.0s/it 1:10.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.837      0.894      0.953      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/100         0G      0.577     0.7356     0.8689         23        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.888      0.901      0.952      0.842\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/100         0G     0.5404     0.6787     0.8547         29        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.754      0.939      0.952      0.819\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/100         0G     0.5977     0.7375     0.8676         31        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.629      0.953      0.956      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/100         0G     0.6314     0.7879     0.9061         10        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.856      0.921       0.91      0.794\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/100         0G     0.5847     0.6897     0.8787         14        640: 100% ━━━━━━━━━━━━ 10/10 7.0s/it 1:10.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.881       0.87      0.969       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/100         0G     0.5631     0.6643     0.8672         14        640: 100% ━━━━━━━━━━━━ 10/10 15.2s/it 2:328sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.817      0.866      0.954      0.852\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/100         0G     0.5293     0.6417     0.8608         22        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.844      0.887      0.945      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/100         0G     0.5318     0.6883      0.861          9        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.6ssss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.902       0.87      0.973      0.866\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/100         0G     0.5431     0.6682     0.8669         15        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.802      0.818      0.978      0.882\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/100         0G       0.51      0.607     0.8507          8        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.7ssss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.675      0.884      0.892      0.805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/100         0G     0.5584     0.6894     0.8764         14        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.851      0.856      0.972       0.88\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/100         0G     0.5751     0.6778     0.8766         31        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.9sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.772      0.873      0.962      0.866\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/100         0G     0.5215     0.6306     0.8633         32        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21       0.91      0.871      0.983      0.896\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/100         0G     0.5135      0.633     0.8592         18        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.906      0.917      0.995      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/100         0G     0.5223     0.6194     0.8635         18        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.872      0.908      0.989       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/100         0G     0.5217     0.5896     0.8568         26        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.7ssss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.857      0.878      0.984      0.893\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/100         0G     0.5177     0.6211     0.8443          6        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.882       0.86      0.984      0.904\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/100         0G      0.534     0.6105     0.8599         27        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21        0.9       0.89      0.984      0.866\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/100         0G     0.4893     0.5323     0.8472         17        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.895      0.886      0.984      0.885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/100         0G     0.4973     0.5667     0.8664         12        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.884      0.925      0.984      0.901\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/100         0G     0.5004      0.582     0.8666         11        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.873      0.922      0.979      0.885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/100         0G     0.5163      0.568     0.8503          9        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.874      0.917      0.979      0.886\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/100         0G     0.4946     0.5857     0.8678         11        640: 100% ━━━━━━━━━━━━ 10/10 7.6s/it 1:16.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.868      0.899      0.984      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/100         0G     0.4859     0.5676     0.8527         37        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.916      0.919      0.984      0.901\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/100         0G     0.4636     0.4994     0.8311         21        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.883      0.919      0.979      0.895\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/100         0G     0.4906      0.555     0.8635         17        640: 100% ━━━━━━━━━━━━ 10/10 7.3s/it 1:13.8sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.877      0.921      0.979      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/100         0G     0.4968     0.5733     0.8559          8        640: 100% ━━━━━━━━━━━━ 10/10 7.3s/it 1:13.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1s/it 2.1s\n",
            "                   all         12         21      0.883      0.932      0.979      0.884\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/100         0G     0.4745     0.5217     0.8439         14        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.899      0.905      0.986      0.914\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/100         0G     0.3954     0.4267     0.8107         14        640: 100% ━━━━━━━━━━━━ 10/10 6.9s/it 1:09.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.899      0.873      0.995      0.921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/100         0G     0.3697     0.3968     0.8183         17        640: 100% ━━━━━━━━━━━━ 10/10 6.9s/it 1:09.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
            "                   all         12         21      0.863      0.872      0.995      0.909\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/100         0G     0.4048     0.4162     0.8195         13        640: 100% ━━━━━━━━━━━━ 10/10 14.0s/it 2:207sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.902      0.868      0.995      0.914\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/100         0G      0.395     0.4008     0.8228         13        640: 100% ━━━━━━━━━━━━ 10/10 6.9s/it 1:09.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.929      0.899      0.995      0.927\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     95/100         0G     0.3823     0.3896     0.8099          6        640: 100% ━━━━━━━━━━━━ 10/10 7.3s/it 1:13.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1s/it 2.1s\n",
            "                   all         12         21      0.948      0.912      0.995      0.917\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     96/100         0G     0.3784     0.3801     0.8293         21        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.7ssss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.944      0.928      0.995      0.928\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     97/100         0G     0.3628     0.3677     0.8094         21        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
            "                   all         12         21      0.949      0.934      0.995       0.93\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     98/100         0G     0.3771     0.3816     0.8296          8        640: 100% ━━━━━━━━━━━━ 10/10 7.0s/it 1:10.6ssss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1s/it 2.1s\n",
            "                   all         12         21      0.947      0.932      0.995       0.93\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     99/100         0G     0.3682     0.3808     0.8199          8        640: 100% ━━━━━━━━━━━━ 10/10 7.1s/it 1:11.6ssss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1s/it 2.1s\n",
            "                   all         12         21      0.944      0.932      0.995      0.928\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    100/100         0G     0.3461     0.3606     0.8037         13        640: 100% ━━━━━━━━━━━━ 10/10 7.2s/it 1:12.7sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1s/it 2.1s\n",
            "                   all         12         21      0.936      0.926      0.995      0.936\n",
            "\n",
            "100 epochs completed in 2.121 hours.\n",
            "Optimizer stripped from C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\last.pt, 5.5MB\n",
            "Optimizer stripped from C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.pt, 5.5MB\n",
            "\n",
            "Validating C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.pt...\n",
            "Ultralytics 8.4.7  Python-3.10.11 torch-2.9.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
            "YOLOv12n summary (fused): 159 layers, 2,558,483 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8s/it 1.8s\n",
            "                   all         12         21      0.936      0.926      0.995      0.936\n",
            "                   Cat          1          1      0.894          1      0.995      0.995\n",
            "                   Dog          2          2       0.88          1      0.995      0.995\n",
            "                   Pig          1          1      0.891          1      0.995      0.995\n",
            "                  bird          2          2      0.991          1      0.995      0.949\n",
            "                   cow          1          1       0.82          1      0.995      0.995\n",
            "                  duck          2          2      0.982          1      0.995      0.995\n",
            "                   hen          4          4          1      0.406      0.995      0.925\n",
            "                 horse          4          4      0.966          1      0.995      0.723\n",
            "                 sheep          4          4          1      0.929      0.995       0.85\n",
            "Speed: 2.5ms preprocess, 134.0ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\u001b[0m\n",
            "\n",
            "Training completed!\n",
            "Best model saved at: C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\n"
          ]
        }
      ],
      "source": [
        "# Train the model with data augmentation\n",
        "results = model.train(\n",
        "    data=str(data_yaml.absolute()),  # Path to data.yaml\n",
        "    epochs=100,                       # Number of training epochs\n",
        "    imgsz=640,                        # Image size\n",
        "    batch=16,                         # Batch size (adjust based on GPU memory)\n",
        "    device=device,                    # Use GPU if available (set in first cell)\n",
        "    workers=8,                        # Number of worker threads\n",
        "    project='runs/detect',            # Project directory\n",
        "    name='yolo12_animal_detection',   # Experiment name\n",
        "    exist_ok=True,                    # Overwrite existing experiment\n",
        "    pretrained=True,                  # Use pretrained weights\n",
        "    optimizer='AdamW',                # Optimizer\n",
        "    verbose=True,                     # Verbose output\n",
        "    seed=42,                          # Random seed for reproducibility\n",
        "    deterministic=True,               # Deterministic training\n",
        "    single_cls=False,                 # Single class mode\n",
        "    rect=False,                       # Rectangular training\n",
        "    cos_lr=False,                     # Cosine LR scheduler\n",
        "    close_mosaic=10,                  # Disable mosaic augmentation in last N epochs\n",
        "    resume=False,                     # Resume from last checkpoint\n",
        "    amp=True,                         # Automatic Mixed Precision\n",
        "    fraction=1.0,                     # Dataset fraction to use\n",
        "    profile=False,                    # Profile ONNX and TensorRT speeds\n",
        "    freeze=None,                      # Freeze layers\n",
        "    # Augmentation parameters\n",
        "    **augmentation_config\n",
        ")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "print(f\"Best model saved at: {results.save_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Evaluate the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.4.7  Python-3.10.11 torch-2.9.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
            "YOLOv12n summary (fused): 159 layers, 2,558,483 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.40.2 ms, read: 18.78.6 MB/s, size: 17.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\CHARBEL\\Desktop\\modelo-animales\\dataset\\valid\\labels.cache... 12 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 12/12  0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7s/it 1.7s\n",
            "                   all         12         21      0.936      0.926      0.995      0.936\n",
            "                   Cat          1          1      0.894          1      0.995      0.995\n",
            "                   Dog          2          2       0.88          1      0.995      0.995\n",
            "                   Pig          1          1      0.891          1      0.995      0.995\n",
            "                  bird          2          2      0.991          1      0.995      0.949\n",
            "                   cow          1          1       0.82          1      0.995      0.995\n",
            "                  duck          2          2      0.982          1      0.995      0.995\n",
            "                   hen          4          4          1      0.406      0.995      0.925\n",
            "                 horse          4          4      0.966          1      0.995      0.723\n",
            "                 sheep          4          4          1      0.929      0.995       0.85\n",
            "Speed: 2.0ms preprocess, 131.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\val\u001b[0m\n",
            "\n",
            "Validation Metrics:\n",
            "mAP50: 0.9950\n",
            "mAP50-95: 0.9357\n",
            "Precision: 0.9359\n",
            "Recall: 0.9261\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on validation set\n",
        "metrics = model.val()\n",
        "print(\"\\nValidation Metrics:\")\n",
        "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
        "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall: {metrics.box.mr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Export the Model\n",
        "\n",
        "Export the trained model to various formats (ONNX, TensorRT, CoreML, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exporting to ONNX format...\n",
            "Ultralytics 8.4.7  Python-3.10.11 torch-2.9.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 13, 8400) (5.3 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.82...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.4s, saved as 'C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx' (10.1 MB)\n",
            "\n",
            "Export complete (2.7s)\n",
            "Results saved to \u001b[1mC:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx imgsz=640 \n",
            "Validate:        yolo val task=detect model=C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx imgsz=640 data=c:\\Users\\CHARBEL\\Desktop\\modelo-animales\\dataset\\data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "ONNX model saved at: C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx\n",
            "Skipping CoreML export (not supported on Windows - requires macOS or Linux)\n",
            "Exporting to TensorFlow Lite format...\n",
            "Ultralytics 8.4.7  Python-3.10.11 torch-2.9.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 13, 8400) (5.3 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['ai-edge-litert>=1.2.0'] not found, attempting AutoUpdate...\n",
            "WARNING Retry 1/2 failed: Command 'uv pip install --no-cache-dir --python \"c:\\Users\\CHARBEL\\Desktop\\modelo-animales\\.venv\\Scripts\\python.exe\" \"ai-edge-litert>=1.2.0\" --extra-index-url https://pypi.ngc.nvidia.com --index-strategy=unsafe-best-match --break-system-packages' returned non-zero exit status 2.\n",
            "WARNING Retry 2/2 failed: Command 'uv pip install --no-cache-dir --python \"c:\\Users\\CHARBEL\\Desktop\\modelo-animales\\.venv\\Scripts\\python.exe\" \"ai-edge-litert>=1.2.0\" --extra-index-url https://pypi.ngc.nvidia.com --index-strategy=unsafe-best-match --break-system-packages' returned non-zero exit status 2.\n",
            "WARNING \u001b[31m\u001b[1mrequirements:\u001b[0m  Command 'uv pip install --no-cache-dir --python \"c:\\Users\\CHARBEL\\Desktop\\modelo-animales\\.venv\\Scripts\\python.exe\" \"ai-edge-litert>=1.2.0\" --extra-index-url https://pypi.ngc.nvidia.com --index-strategy=unsafe-best-match --break-system-packages' returned non-zero exit status 2.\n",
            "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Request failed after 3 retries\n",
            "  \u001b[1m\u001b[31mCaused by\u001b[39m\u001b[0m: Failed to fetch: `https://pypi.ngc.nvidia.com/ai-edge-litert/`\n",
            "  \u001b[1m\u001b[31mCaused by\u001b[39m\u001b[0m: error sending request for url (https://pypi.ngc.nvidia.com/ai-edge-litert/)\n",
            "  \u001b[1m\u001b[31mCaused by\u001b[39m\u001b[0m: client error (Connect)\n",
            "  \u001b[1m\u001b[31mCaused by\u001b[39m\u001b[0m: Se ha forzado la interrupcin de una conexin existente por el host remoto. (os error 10054)\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.20.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.82...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.9s, saved as 'C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx' (10.2 MB)\n",
            "ERROR \u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export failure 17.7s: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'\n",
            "TensorFlow Lite export failed: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'\n",
            "Note: TensorFlow Lite export has known compatibility issues on Windows.\n",
            "The ONNX format (exported above) is recommended for deployment and works on all platforms.\n",
            "\n",
            "All exports completed!\n",
            "\n",
            "Summary:\n",
            "✓ ONNX model: C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx\n",
            "Note: ONNX is the recommended format for cross-platform deployment.\n"
          ]
        }
      ],
      "source": [
        "# Export model to different formats\n",
        "export_dir = Path(\"exports\")\n",
        "export_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Check platform\n",
        "import platform\n",
        "is_windows = platform.system() == 'Windows'\n",
        "is_macos = platform.system() == 'Darwin'\n",
        "\n",
        "# Export to ONNX (recommended for deployment)\n",
        "print(\"Exporting to ONNX format...\")\n",
        "onnx_path = model.export(format='onnx', imgsz=640, optimize=True)\n",
        "print(f\"ONNX model saved at: {onnx_path}\")\n",
        "\n",
        "# Export to TensorRT (for NVIDIA GPUs)\n",
        "# Uncomment if you have TensorRT installed\n",
        "# print(\"Exporting to TensorRT format...\")\n",
        "# trt_path = model.export(format='engine', imgsz=640)\n",
        "# print(f\"TensorRT model saved at: {trt_path}\")\n",
        "\n",
        "# Export to CoreML (for Apple devices - macOS/Linux only)\n",
        "if not is_windows:\n",
        "    print(\"Exporting to CoreML format...\")\n",
        "    try:\n",
        "        coreml_path = model.export(format='coreml', imgsz=640)\n",
        "        print(f\"CoreML model saved at: {coreml_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"CoreML export failed: {e}\")\n",
        "else:\n",
        "    print(\"Skipping CoreML export (not supported on Windows - requires macOS or Linux)\")\n",
        "\n",
        "# Export to TensorFlow Lite (for mobile devices)\n",
        "# Note: TensorFlow Lite export may have compatibility issues on Windows\n",
        "# ONNX format (exported above) is recommended for cross-platform deployment\n",
        "print(\"Exporting to TensorFlow Lite format...\")\n",
        "try:\n",
        "    tflite_path = model.export(format='tflite', imgsz=640)\n",
        "    print(f\"TensorFlow Lite model saved at: {tflite_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"TensorFlow Lite export failed: {e}\")\n",
        "    print(\"Note: TensorFlow Lite export has known compatibility issues on Windows.\")\n",
        "    print(\"The ONNX format (exported above) is recommended for deployment and works on all platforms.\")\n",
        "\n",
        "print(\"\\nAll exports completed!\")\n",
        "print(\"\\nSummary:\")\n",
        "print(f\"✓ ONNX model: {onnx_path}\")\n",
        "if not is_windows:\n",
        "    print(f\"✓ CoreML model: {coreml_path if 'coreml_path' in locals() else 'Not exported'}\")\n",
        "print(\"Note: ONNX is the recommended format for cross-platform deployment.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Test the Exported Model (Optional)\n",
        "\n",
        "Test the exported ONNX model to verify it works correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing on 3 sample images...\n",
            "Loading C:\\Users\\CHARBEL\\Desktop\\Lingo\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx for ONNX Runtime inference...\n",
            "Using ONNX Runtime 1.23.2 with CPUExecutionProvider\n",
            "\n"
          ]
        },
        {
          "ename": "InvalidArgument",
          "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: images for the following indices\n index: 0 Got: 3 Expected: 1\n Please fix either the inputs/outputs or the model.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_images:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sample images...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43monnx_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_txt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43miou\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.45\u001b[39;49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions completed! Check the runs/detect directory for results.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\CHARBEL\\Desktop\\modelo-animales\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py:536\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\CHARBEL\\Desktop\\modelo-animales\\.venv\\lib\\site-packages\\ultralytics\\engine\\predictor.py:225\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\CHARBEL\\Desktop\\modelo-animales\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:38\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 38\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\CHARBEL\\Desktop\\modelo-animales\\.venv\\lib\\site-packages\\ultralytics\\engine\\predictor.py:330\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 330\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\CHARBEL\\Desktop\\modelo-animales\\.venv\\lib\\site-packages\\ultralytics\\engine\\predictor.py:182\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    177\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    178\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    181\u001b[0m )\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\CHARBEL\\Desktop\\modelo-animales\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\CHARBEL\\Desktop\\modelo-animales\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\CHARBEL\\Desktop\\modelo-animales\\.venv\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:730\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    729\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# torch to numpy\u001b[39;00m\n\u001b[1;32m--> 730\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimx:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    733\u001b[0m         \u001b[38;5;66;03m# boxes, conf, cls\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\CHARBEL\\Desktop\\modelo-animales\\.venv\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:287\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    285\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
            "\u001b[1;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: images for the following indices\n index: 0 Got: 3 Expected: 1\n Please fix either the inputs/outputs or the model."
          ]
        }
      ],
      "source": [
        "# Load and test the exported ONNX model\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the exported ONNX model\n",
        "onnx_model = YOLO(onnx_path)\n",
        "\n",
        "# Test on a sample image\n",
        "test_image_path = dataset_path / \"test\" / \"images\"\n",
        "if test_image_path.exists():\n",
        "    test_images = list(test_image_path.glob(\"*.jpg\"))[:3]  # Test on first 3 images\n",
        "    if test_images:\n",
        "        print(f\"Testing on {len(test_images)} sample images...\")\n",
        "        results = onnx_model.predict(\n",
        "            source=[str(img) for img in test_images],\n",
        "            save=True,\n",
        "            save_txt=True,\n",
        "            conf=0.25,\n",
        "            iou=0.45\n",
        "        )\n",
        "        print(\"Predictions completed! Check the runs/detect directory for results.\")\n",
        "    else:\n",
        "        print(\"No test images found.\")\n",
        "else:\n",
        "    print(\"Test images directory not found.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
