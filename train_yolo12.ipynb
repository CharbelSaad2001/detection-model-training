{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLO 12 Model Training with Data Augmentation\n",
        "\n",
        "This notebook trains a YOLO 12 model on the animal detection dataset with data augmentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n",
            "Device: cuda\n",
            "GPU: NVIDIA GeForce RTX 3060\n",
            "Dataset path: d:\\labbd-2\\Downloads\\TesisAnimales.v3i.yolov12\n",
            "Data YAML: d:\\labbd-2\\Downloads\\TesisAnimales.v3i.yolov12\\data.yaml\n",
            "¿Torch detecta CUDA?: True\n",
            "Versión de CUDA en Torch: 11.8\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import torch\n",
        "\n",
        "# Set up paths\n",
        "dataset_path = Path(\"d:/labbd-2/Downloads/TesisAnimales.v3i.yolov12\")\n",
        "data_yaml = dataset_path / \"data.yaml\"\n",
        "\n",
        "# Check device availability\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Device: {device}\")\n",
        "if device == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"Dataset path: {dataset_path.absolute()}\")\n",
        "print(f\"Data YAML: {data_yaml.absolute()}\")\n",
        "\n",
        "print(f\"¿Torch detecta CUDA?: {torch.cuda.is_available()}\")\n",
        "print(f\"Versión de CUDA en Torch: {torch.version.cuda}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Verify Dataset Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Configuration:\n",
            "Number of classes: 43\n",
            "Class names: ['Cat', 'Dog', 'Pig', 'Skateboard', 'Train', 'Van', 'apple', 'backpack', 'banana', 'bike', 'bird', 'book', 'bus', 'cake', 'cap', 'car', 'colors', 'cow', 'duck', 'eraser', 'glasses', 'hamburger', 'hen', 'horse', 'hot dog', 'milkshakes', 'motorbike', 'notebook', 'orange', 'pants', 'pencil', 'pizza', 'potatoes', 'ruler', 'sandals', 'sheep', 'shirt', 'shoes', 'socks', 'soda', 'spaghetti', 'strawberry', 'sweater']\n",
            "Train path: ../train/images\n",
            "Validation path: ../valid/images\n",
            "Test path: ../test/images\n",
            "\n",
            "Path verification:\n",
            "Train images exist: False\n",
            "Validation images exist: False\n",
            "Test images exist: False\n"
          ]
        }
      ],
      "source": [
        "# Verify data.yaml configuration\n",
        "with open(data_yaml, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "    \n",
        "print(\"Dataset Configuration:\")\n",
        "print(f\"Number of classes: {config['nc']}\")\n",
        "print(f\"Class names: {config['names']}\")\n",
        "print(f\"Train path: {config['train']}\")\n",
        "print(f\"Validation path: {config['val']}\")\n",
        "print(f\"Test path: {config['test']}\")\n",
        "\n",
        "# Verify paths exist\n",
        "train_path = dataset_path / config['train']\n",
        "val_path = dataset_path / config['val']\n",
        "test_path = dataset_path / config['test']\n",
        "\n",
        "print(f\"\\nPath verification:\")\n",
        "print(f\"Train images exist: {train_path.exists()}\")\n",
        "print(f\"Validation images exist: {val_path.exists()}\")\n",
        "print(f\"Test images exist: {test_path.exists()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Initialize YOLO 12 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO 12 model initialized!\n",
            "Model type: detect\n"
          ]
        }
      ],
      "source": [
        "# Initialize YOLO 12 model\n",
        "# Using yolov12n (nano) for faster training, can be changed to yolov12s, yolov12m, yolov12l, yolov12x\n",
        "model = YOLO('yolo12n.pt')  # Downloads pretrained weights automatically\n",
        "\n",
        "print(\"YOLO 12 model initialized!\")\n",
        "print(f\"Model type: {model.task}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Configure Data Augmentation\n",
        "\n",
        "Data augmentation helps improve model generalization by creating variations of training images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Augmentation Configuration:\n",
            "  hsv_h: 0.015\n",
            "  hsv_s: 0.7\n",
            "  hsv_v: 0.4\n",
            "  degrees: 10.0\n",
            "  translate: 0.1\n",
            "  scale: 0.5\n",
            "  shear: 2.0\n",
            "  perspective: 0.0\n",
            "  flipud: 0.0\n",
            "  fliplr: 0.5\n",
            "  mosaic: 1.0\n",
            "  mixup: 0.1\n",
            "  copy_paste: 0.1\n"
          ]
        }
      ],
      "source": [
        "# Configure data augmentation parameters\n",
        "# These augmentations will be applied during training\n",
        "augmentation_config = {\n",
        "    'hsv_h': 0.015,      # Hue augmentation (0-1)\n",
        "    'hsv_s': 0.7,        # Saturation augmentation (0-1)\n",
        "    'hsv_v': 0.4,        # Value augmentation (0-1)\n",
        "    'degrees': 10.0,     # Rotation degrees\n",
        "    'translate': 0.1,    # Translation (fraction of image size)\n",
        "    'scale': 0.5,        # Scale augmentation (0-1)\n",
        "    'shear': 2.0,        # Shear degrees\n",
        "    'perspective': 0.0,  # Perspective augmentation (0-0.001)\n",
        "    'flipud': 0.0,       # Vertical flip probability (0-1)\n",
        "    'fliplr': 0.5,       # Horizontal flip probability (0-1)\n",
        "    'mosaic': 1.0,       # Mosaic augmentation probability (0-1)\n",
        "    'mixup': 0.1,        # Mixup augmentation probability (0-1)\n",
        "    'copy_paste': 0.1,   # Copy-paste augmentation probability (0-1)\n",
        "}\n",
        "\n",
        "print(\"Data Augmentation Configuration:\")\n",
        "for key, value in augmentation_config.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Train the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.4.9 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.4.7  Python-3.12.2 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=d:\\labbd-2\\Downloads\\TesisAnimales.v3i.yolov12\\data.yaml, degrees=10.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolo12n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolo12_animal_detection, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=2.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=43\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  2    180864  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
            "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
            " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
            " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
            " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 21        [14, 17, 20]  1    439057  ultralytics.nn.modules.head.Detect           [43, 16, None, [64, 128, 256]]\n",
            "YOLOv12n summary: 272 layers, 2,576,433 parameters, 2,576,417 gradients, 6.5 GFLOPs\n",
            "\n",
            "Transferred 640/691 items from pretrained weights\n",
            "Freezing layer 'model.21.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ━━━━━━━━━━━━ 5.3MB 1.3MB/s 3.9s.9s<0.1s5ss4.9s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 68.626.8 MB/s, size: 11.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\labbd-2\\Downloads\\TesisAnimales.v3i.yolov12\\train\\labels.cache... 1512 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1512/1512  0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 58.235.7 MB/s, size: 13.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\labbd-2\\Downloads\\TesisAnimales.v3i.yolov12\\valid\\labels.cache... 146 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 146/146  0.0s\n",
            "Plotting labels to C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mC:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      3.38G     0.9973      3.843      1.049         20        640: 100% ━━━━━━━━━━━━ 95/95 5.5it/s 17.4s0.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 6.2it/s 0.8s0.2s\n",
            "                   all        146        279   1.83e-05     0.0047   1.03e-05   4.67e-06\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      3.76G     0.8806      2.823      1.034         34        640: 100% ━━━━━━━━━━━━ 95/95 5.8it/s 16.4s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 2.9it/s 1.7s0.5s\n",
            "                   all        146        279      0.205      0.253       0.12     0.0888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      3.77G     0.8343      2.452      1.043         22        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.0it/s 1.7s0.5s\n",
            "                   all        146        279      0.422      0.253      0.243      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      3.77G     0.7708      2.154      1.023         32        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 6.6it/s 0.8s0.2s\n",
            "                   all        146        279      0.513      0.419      0.366      0.302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      3.77G      0.728      1.978      1.014         23        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.0s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 6.8it/s 0.7s0.2s\n",
            "                   all        146        279      0.362      0.447      0.413       0.35\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      3.79G     0.6988      1.779      1.001         44        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.4it/s 0.7s0.2s\n",
            "                   all        146        279      0.533      0.579      0.549      0.471\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100      3.79G      0.665      1.653     0.9723         16        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.4it/s 0.7s0.2s\n",
            "                   all        146        279      0.373      0.671       0.61      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      3.79G     0.6402      1.463     0.9679         20        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.545      0.665      0.719      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      3.79G      0.635       1.36     0.9647         40        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.4it/s 0.7s0.2s\n",
            "                   all        146        279      0.651      0.659      0.731      0.655\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      3.79G     0.6162      1.324     0.9631         19        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.708      0.629      0.777      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100      3.79G     0.6051      1.264     0.9503         23        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.726      0.667      0.771      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100      3.79G     0.5955      1.192     0.9483         51        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.4it/s 0.7s0.2s\n",
            "                   all        146        279       0.77      0.722       0.83      0.739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100      3.79G     0.5849      1.182     0.9465         31        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.692      0.642      0.746      0.669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100       3.8G     0.5789      1.125     0.9394         32        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.731      0.807      0.874      0.787\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100       3.8G     0.5793      1.017     0.9308         41        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.726      0.712      0.802      0.724\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100       3.8G     0.5628      1.026      0.927         34        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.743      0.795      0.864       0.78\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100       3.8G     0.5565     0.9702     0.9235         39        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.784      0.752      0.847      0.783\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100       3.8G     0.5539     0.9706     0.9293         30        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.748      0.837      0.892       0.82\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100       3.8G     0.5353     0.8959     0.9153         22        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.4it/s 0.7s0.2s\n",
            "                   all        146        279      0.771      0.754      0.846      0.763\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100       3.8G      0.537     0.8898     0.9122         34        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.4it/s 0.7s0.2s\n",
            "                   all        146        279      0.689      0.677      0.797       0.73\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100       3.8G     0.5307     0.8553     0.9105         39        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.759      0.844      0.899      0.826\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/100       3.8G     0.5407      0.885     0.9163         23        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.874      0.775      0.905      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/100       3.8G     0.5257     0.8611     0.9164         32        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279       0.87      0.849      0.943      0.878\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/100       3.8G     0.5184     0.8177     0.9051         22        640: 100% ━━━━━━━━━━━━ 95/95 5.8it/s 16.3s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.785       0.78      0.901      0.836\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/100       3.8G     0.5017     0.7847     0.9033         15        640: 100% ━━━━━━━━━━━━ 95/95 5.8it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.818      0.847      0.941      0.873\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/100       3.8G     0.5006     0.8034      0.901         28        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.844      0.873      0.927      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/100       3.8G     0.5261     0.7731     0.9059         35        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.824      0.808      0.927      0.866\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/100       3.8G      0.495      0.735     0.8998         49        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.883      0.877      0.952      0.891\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/100       3.8G     0.4904      0.745     0.8937         28        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.748       0.86       0.89      0.828\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/100       3.8G     0.4832     0.7218     0.8921         22        640: 100% ━━━━━━━━━━━━ 95/95 5.8it/s 16.3s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.817      0.837      0.904       0.82\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/100       3.8G     0.4853      0.705     0.8957         17        640: 100% ━━━━━━━━━━━━ 95/95 5.8it/s 16.3s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.885      0.894       0.95      0.894\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/100       3.8G     0.4851     0.6817     0.8874         37        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279        0.9      0.904      0.965      0.907\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/100       3.8G     0.4749     0.6612     0.8883         22        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.916       0.91      0.964      0.918\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/100       3.8G      0.476     0.6482     0.8869         22        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.907      0.916      0.966       0.91\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/100       3.8G     0.4687     0.6479     0.8823         36        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.889      0.861      0.953      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/100       3.8G     0.4759      0.635     0.8815         36        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.908       0.89      0.955      0.899\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/100       3.8G     0.4779     0.6449     0.8855         17        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.888      0.929      0.974      0.908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/100       3.8G     0.4712     0.6105     0.8841         29        640: 100% ━━━━━━━━━━━━ 95/95 5.8it/s 16.3s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.883      0.935      0.972      0.914\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/100       3.8G     0.4663     0.6182     0.8843         29        640: 100% ━━━━━━━━━━━━ 95/95 5.8it/s 16.3s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.866      0.912      0.958      0.892\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/100       3.8G     0.4638     0.6078     0.8775         11        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.882      0.884       0.95      0.882\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/100       3.8G     0.4543     0.5937     0.8747         26        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.883      0.924      0.971      0.919\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/100       3.8G     0.4597     0.5925     0.8777         23        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.891      0.905      0.969      0.921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/100       3.8G     0.4439     0.5811     0.8709         38        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279        0.9      0.902      0.964       0.91\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/100       3.8G      0.455     0.5813     0.8775         27        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.927      0.919      0.968      0.927\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/100       3.8G     0.4452     0.5635     0.8758          8        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.933       0.95       0.98      0.929\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/100       3.8G     0.4469     0.5713     0.8738         40        640: 100% ━━━━━━━━━━━━ 95/95 5.8it/s 16.2s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.926      0.941      0.978      0.926\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/100       3.8G     0.4589      0.554     0.8818         25        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.925      0.935      0.978      0.928\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/100       3.8G       0.44     0.5384      0.872         38        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279       0.93       0.94       0.97      0.921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/100       3.8G     0.4322     0.5379     0.8774         16        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.909      0.918      0.972      0.915\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/100       3.8G     0.4373     0.5697     0.8779         23        640: 100% ━━━━━━━━━━━━ 95/95 5.8it/s 16.2s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.923      0.954      0.978      0.926\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/100       3.8G     0.4295     0.5518     0.8688         26        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.931      0.957      0.982      0.937\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/100       3.8G     0.4403     0.5284     0.8673         18        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.899      0.922      0.976      0.925\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/100       3.8G     0.4342     0.5235     0.8658         36        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.923      0.925      0.975      0.932\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/100       3.8G     0.4284     0.5158     0.8672         49        640: 100% ━━━━━━━━━━━━ 95/95 5.8it/s 16.2s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.935      0.935       0.97      0.919\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/100       3.8G     0.4332     0.5122     0.8637         38        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.929      0.945      0.974      0.927\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/100       3.8G     0.4296     0.5092     0.8662         34        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.923      0.941      0.978      0.924\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/100       3.8G     0.4351     0.5221     0.8739         25        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.941      0.942      0.983      0.935\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/100       3.8G     0.4185     0.4846      0.864         22        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.919      0.942      0.973      0.931\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/100       3.8G     0.4258     0.4968     0.8611         19        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.941      0.955      0.976      0.931\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/100       3.8G      0.428     0.4821     0.8651         46        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.937      0.947      0.977       0.93\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/100       3.8G     0.4145     0.4637     0.8648         20        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279       0.93      0.958      0.981       0.94\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/100       3.8G     0.4168     0.4882     0.8665         20        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.921      0.958       0.98      0.939\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/100       3.8G     0.4162     0.4793     0.8613         23        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.936      0.951      0.978      0.932\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/100       3.8G     0.4069     0.4696     0.8596         25        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.941      0.952      0.977      0.935\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/100       3.8G     0.4095     0.4541     0.8596         40        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.937      0.963      0.975      0.933\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/100       3.8G     0.4072     0.4566     0.8568         24        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.948      0.958      0.979      0.941\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/100       3.8G     0.4027     0.4681     0.8585         25        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.921      0.956      0.978      0.941\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/100       3.8G     0.4015     0.4556     0.8563         24        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.929      0.939      0.979      0.937\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/100       3.8G     0.4086     0.4569     0.8642         20        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.949      0.934      0.977      0.937\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/100       3.8G     0.4137     0.4591     0.8628         31        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.0s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.7s0.2s\n",
            "                   all        146        279      0.934      0.951      0.972      0.928\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/100       3.8G     0.4076     0.4532     0.8626         18        640: 100% ━━━━━━━━━━━━ 95/95 5.8it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.917      0.956      0.974      0.937\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/100       3.8G     0.4098     0.4418     0.8614         28        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279       0.95      0.954      0.976      0.935\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/100       3.8G      0.394     0.4348     0.8549         29        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.2s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.936      0.948      0.976      0.935\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/100       3.8G     0.3971     0.4381     0.8561         40        640: 100% ━━━━━━━━━━━━ 95/95 5.8it/s 16.3s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.7s0.2s\n",
            "                   all        146        279      0.939      0.939      0.979      0.943\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/100       3.8G     0.3976      0.431     0.8627         29        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.8s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.6s0.2s\n",
            "                   all        146        279      0.938      0.954      0.983      0.948\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/100       3.8G     0.4001     0.4447     0.8592         19        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.8s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.6s0.2s\n",
            "                   all        146        279      0.934      0.949      0.977      0.942\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/100       3.8G      0.395     0.4251     0.8523         44        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.8s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.6s0.2s\n",
            "                   all        146        279       0.95      0.951       0.98      0.938\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/100       3.8G       0.39     0.4153     0.8502         34        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.8s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.6s0.2s\n",
            "                   all        146        279      0.954      0.954       0.98      0.947\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/100       3.8G     0.3849     0.4149     0.8555         37        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.8s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.6s0.2s\n",
            "                   all        146        279      0.936      0.966       0.98       0.95\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/100       3.8G     0.3901     0.4143     0.8527         50        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.8s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.6s0.2s\n",
            "                   all        146        279      0.955      0.955       0.98       0.94\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/100       3.8G     0.3855     0.4023     0.8472         35        640: 100% ━━━━━━━━━━━━ 95/95 5.7it/s 16.6s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.4it/s 0.7s0.2s\n",
            "                   all        146        279      0.955      0.959      0.985      0.948\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/100       3.8G     0.3851     0.4082     0.8527         23        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.8s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.955      0.972      0.984      0.948\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/100       3.8G     0.3765     0.3955      0.848         59        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.7s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.6s0.2s\n",
            "                   all        146        279       0.95      0.958      0.983      0.941\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/100       3.8G     0.3833     0.3895      0.852         12        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.7s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.6s0.2s\n",
            "                   all        146        279      0.946      0.967      0.981      0.937\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/100       3.8G     0.3821     0.3875     0.8503         41        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.7s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.8it/s 0.6s0.2s\n",
            "                   all        146        279       0.95      0.964      0.984      0.951\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/100       3.8G     0.3829     0.4005     0.8514         22        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.8s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.6s0.2s\n",
            "                   all        146        279      0.952      0.965      0.983      0.947\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/100       3.8G     0.3829     0.4038     0.8543         38        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.7s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.8it/s 0.6s0.2s\n",
            "                   all        146        279      0.944       0.96      0.983       0.95\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/100       3.8G     0.3783     0.3935       0.85         25        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.7s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.6s0.2s\n",
            "                   all        146        279      0.959      0.972      0.985      0.949\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/100       3.8G     0.3721     0.3821     0.8403         17        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.7s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.6s0.2s\n",
            "                   all        146        279      0.957      0.963      0.981      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/100       3.8G      0.372      0.383     0.8415         22        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.7s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.8it/s 0.6s0.2s\n",
            "                   all        146        279      0.949      0.965      0.982      0.946\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/100       3.8G     0.3305     0.2815     0.8364          9        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 15.8s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.8it/s 0.6s0.2s\n",
            "                   all        146        279       0.96      0.954       0.98      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/100       3.8G     0.3225     0.2767     0.8332         14        640: 100% ━━━━━━━━━━━━ 95/95 6.1it/s 15.5s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.8it/s 0.6s0.2s\n",
            "                   all        146        279      0.954      0.958      0.981      0.946\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/100       3.8G     0.3146     0.2736     0.8279         13        640: 100% ━━━━━━━━━━━━ 95/95 6.1it/s 15.5s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.8it/s 0.6s0.2s\n",
            "                   all        146        279      0.967      0.965      0.982       0.95\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/100       3.8G      0.319     0.2733     0.8324         29        640: 100% ━━━━━━━━━━━━ 95/95 6.1it/s 15.5s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.6s0.2s\n",
            "                   all        146        279      0.959      0.966      0.982      0.952\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     95/100       3.8G     0.3181     0.2715     0.8324         26        640: 100% ━━━━━━━━━━━━ 95/95 6.1it/s 15.5s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7it/s 0.6s0.2s\n",
            "                   all        146        279      0.954      0.966      0.983      0.951\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     96/100       3.8G     0.3123     0.2667      0.831         14        640: 100% ━━━━━━━━━━━━ 95/95 6.1it/s 15.6s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.8it/s 0.6s0.2s\n",
            "                   all        146        279      0.954      0.964      0.982       0.95\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     97/100       3.8G     0.3153     0.2611     0.8285         15        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.963      0.965      0.983      0.952\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     98/100       3.8G      0.307     0.2619     0.8278          7        640: 100% ━━━━━━━━━━━━ 95/95 6.0it/s 16.0s0.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279      0.962      0.965      0.983      0.953\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     99/100       3.8G     0.3032     0.2526      0.831         26        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.0s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.5it/s 0.7s0.2s\n",
            "                   all        146        279      0.961      0.963      0.982      0.951\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    100/100       3.8G     0.2987     0.2489     0.8208         23        640: 100% ━━━━━━━━━━━━ 95/95 5.9it/s 16.1s0.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6it/s 0.7s0.2s\n",
            "                   all        146        279       0.96      0.966      0.982      0.951\n",
            "\n",
            "100 epochs completed in 0.475 hours.\n",
            "Optimizer stripped from C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\last.pt, 5.5MB\n",
            "Optimizer stripped from C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.pt, 5.5MB\n",
            "\n",
            "Validating C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.pt...\n",
            "Ultralytics 8.4.7  Python-3.12.2 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
            "YOLOv12n summary (fused): 159 layers, 2,565,113 parameters, 0 gradients, 6.4 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 6.5it/s 0.8s0.2s\n",
            "                   all        146        279      0.962      0.965      0.983      0.953\n",
            "                   Cat          7          7      0.855          1       0.96      0.927\n",
            "                   Dog          7          7       0.99          1      0.995      0.995\n",
            "                   Pig          3          3      0.943          1      0.995      0.953\n",
            "            Skateboard          4          4      0.982          1      0.995      0.965\n",
            "                 Train          9          9      0.989          1      0.995      0.984\n",
            "                   Van          8          8      0.984          1      0.995      0.995\n",
            "                 apple          7          7       0.86      0.881       0.96      0.909\n",
            "              backpack          8          8      0.991          1      0.995      0.975\n",
            "                banana          9          9      0.965          1      0.995       0.95\n",
            "                  bike          7          7      0.979          1      0.995      0.995\n",
            "                  bird          6          6      0.977      0.833      0.866      0.838\n",
            "                  book          3          3      0.963          1      0.995      0.995\n",
            "                   bus          8          8      0.985          1      0.995      0.995\n",
            "                  cake          9          9          1      0.798      0.995       0.98\n",
            "                   cap          6          6          1      0.997      0.995      0.977\n",
            "                   car          5          5      0.967        0.8       0.82       0.82\n",
            "                colors          6          6      0.983          1      0.995      0.948\n",
            "                   cow          2          2      0.946          1      0.995      0.995\n",
            "                  duck          6          6      0.972          1      0.995      0.995\n",
            "                eraser          6          6      0.981          1      0.995      0.944\n",
            "               glasses          4          4      0.952          1      0.995      0.954\n",
            "             hamburger          8          8      0.902          1      0.995      0.954\n",
            "                   hen         10         10      0.908      0.991      0.986      0.947\n",
            "                 horse         11         11          1      0.928      0.995       0.93\n",
            "               hot dog          8          8      0.979          1      0.995      0.932\n",
            "            milkshakes          9          9          1      0.903      0.995      0.926\n",
            "             motorbike          8          8      0.982          1      0.995       0.98\n",
            "              notebook          6          6      0.982          1      0.995      0.958\n",
            "                orange          7          7          1       0.89      0.995      0.967\n",
            "                 pants          5          5      0.997          1      0.995      0.944\n",
            "                pencil          6          6      0.942          1      0.995      0.891\n",
            "                 pizza          8          9      0.983      0.889      0.928      0.908\n",
            "              potatoes          8          8      0.982          1      0.995      0.981\n",
            "                 ruler          3          3          1          1      0.995      0.931\n",
            "               sandals          9          9      0.983          1      0.995      0.947\n",
            "                 sheep          9          9      0.941      0.889      0.975      0.869\n",
            "                 shirt          4          4      0.965          1      0.995      0.995\n",
            "                 shoes          4          4      0.939          1      0.995      0.972\n",
            "                 socks          3          3      0.924          1      0.995      0.952\n",
            "                  soda          5          5      0.812          1      0.962      0.962\n",
            "             spaghetti          5          5      0.967          1      0.995      0.961\n",
            "            strawberry          6          6      0.928      0.833      0.972      0.972\n",
            "               sweater          6          6          1      0.863      0.995      0.995\n",
            "Speed: 0.1ms preprocess, 2.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\u001b[0m\n",
            "\n",
            "Training completed!\n",
            "Best model saved at: C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\n"
          ]
        }
      ],
      "source": [
        "# Train the model with data augmentation\n",
        "results = model.train(\n",
        "    data=str(data_yaml.absolute()),  # Path to data.yaml\n",
        "    epochs=100,                       # Number of training epochs\n",
        "    imgsz=640,                        # Image size\n",
        "    batch=16,                         # Batch size (adjust based on GPU memory)\n",
        "    device=device,                    # Use GPU if available (set in first cell)\n",
        "    workers=8,                        # Number of worker threads\n",
        "    project='runs/detect',            # Project directory\n",
        "    name='yolo12_animal_detection',   # Experiment name\n",
        "    exist_ok=True,                    # Overwrite existing experiment\n",
        "    pretrained=True,                  # Use pretrained weights\n",
        "    optimizer='AdamW',                # Optimizer\n",
        "    verbose=True,                     # Verbose output\n",
        "    seed=42,                          # Random seed for reproducibility\n",
        "    deterministic=True,               # Deterministic training\n",
        "    single_cls=False,                 # Single class mode\n",
        "    rect=False,                       # Rectangular training\n",
        "    cos_lr=False,                     # Cosine LR scheduler\n",
        "    close_mosaic=10,                  # Disable mosaic augmentation in last N epochs\n",
        "    resume=False,                     # Resume from last checkpoint\n",
        "    amp=True,                         # Automatic Mixed Precision\n",
        "    fraction=1.0,                     # Dataset fraction to use\n",
        "    profile=False,                    # Profile ONNX and TensorRT speeds\n",
        "    freeze=None,                      # Freeze layers\n",
        "    # Augmentation parameters\n",
        "    **augmentation_config\n",
        ")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "print(f\"Best model saved at: {results.save_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Evaluate the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.4.7  Python-3.12.2 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
            "YOLOv12n summary (fused): 159 layers, 2,565,113 parameters, 0 gradients, 6.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 274.9139.9 MB/s, size: 13.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\labbd-2\\Downloads\\TesisAnimales.v3i.yolov12\\valid\\labels.cache... 146 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 146/146  0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 8.1it/s 1.2s.1s\n",
            "                   all        146        279      0.962      0.965      0.983      0.954\n",
            "                   Cat          7          7      0.854          1       0.96      0.927\n",
            "                   Dog          7          7       0.99          1      0.995      0.995\n",
            "                   Pig          3          3      0.943          1      0.995      0.953\n",
            "            Skateboard          4          4      0.982          1      0.995      0.965\n",
            "                 Train          9          9      0.989          1      0.995      0.984\n",
            "                   Van          8          8      0.984          1      0.995      0.995\n",
            "                 apple          7          7       0.86      0.882       0.96      0.909\n",
            "              backpack          8          8      0.991          1      0.995      0.975\n",
            "                banana          9          9      0.965          1      0.995       0.95\n",
            "                  bike          7          7      0.979          1      0.995      0.995\n",
            "                  bird          6          6      0.977      0.833      0.869      0.841\n",
            "                  book          3          3      0.963          1      0.995      0.995\n",
            "                   bus          8          8      0.985          1      0.995      0.995\n",
            "                  cake          9          9          1      0.798      0.995       0.98\n",
            "                   cap          6          6          1      0.998      0.995      0.977\n",
            "                   car          5          5      0.967        0.8       0.82       0.82\n",
            "                colors          6          6      0.983          1      0.995      0.948\n",
            "                   cow          2          2      0.946          1      0.995      0.995\n",
            "                  duck          6          6      0.972          1      0.995       0.98\n",
            "                eraser          6          6      0.981          1      0.995      0.944\n",
            "               glasses          4          4      0.952          1      0.995      0.954\n",
            "             hamburger          8          8        0.9          1      0.995      0.942\n",
            "                   hen         10         10      0.909      0.997      0.986      0.963\n",
            "                 horse         11         11          1      0.928      0.995       0.93\n",
            "               hot dog          8          8      0.979          1      0.995      0.928\n",
            "            milkshakes          9          9          1      0.904      0.995      0.932\n",
            "             motorbike          8          8      0.982          1      0.995       0.98\n",
            "              notebook          6          6      0.982          1      0.995      0.958\n",
            "                orange          7          7          1       0.89      0.995      0.967\n",
            "                 pants          5          5      0.997          1      0.995      0.944\n",
            "                pencil          6          6      0.941          1      0.995      0.891\n",
            "                 pizza          8          9      0.983      0.889      0.928      0.908\n",
            "              potatoes          8          8      0.982          1      0.995      0.981\n",
            "                 ruler          3          3      0.999          1      0.995      0.931\n",
            "               sandals          9          9      0.983          1      0.995      0.966\n",
            "                 sheep          9          9      0.941      0.889      0.975      0.869\n",
            "                 shirt          4          4      0.965          1      0.995      0.995\n",
            "                 shoes          4          4      0.938          1      0.995      0.972\n",
            "                 socks          3          3      0.924          1      0.995      0.995\n",
            "                  soda          5          5      0.812          1      0.962      0.962\n",
            "             spaghetti          5          5      0.967          1      0.995      0.961\n",
            "            strawberry          6          6      0.927      0.833      0.972      0.972\n",
            "               sweater          6          6          1      0.864      0.995      0.995\n",
            "Speed: 1.6ms preprocess, 4.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\val\u001b[0m\n",
            "\n",
            "Validation Metrics:\n",
            "mAP50: 0.9828\n",
            "mAP50-95: 0.9540\n",
            "Precision: 0.9622\n",
            "Recall: 0.9652\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on validation set\n",
        "metrics = model.val()\n",
        "print(\"\\nValidation Metrics:\")\n",
        "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
        "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall: {metrics.box.mr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Export the Model\n",
        "\n",
        "Export the trained model to various formats (ONNX, TensorRT, CoreML, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exporting to ONNX format...\n",
            "Ultralytics 8.4.7  Python-3.12.2 torch-2.7.1+cu118 CPU (13th Gen Intel Core i7-13700F)\n",
            " ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 47, 8400) (5.3 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "WARNING \n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.82...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success  126.8s, saved as 'C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx' (10.1 MB)\n",
            "\n",
            "Export complete (127.0s)\n",
            "Results saved to \u001b[1mC:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx imgsz=640 \n",
            "Validate:        yolo val task=detect model=C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx imgsz=640 data=d:\\labbd-2\\Downloads\\TesisAnimales.v3i.yolov12\\data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "ONNX model saved at: C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx\n",
            "Skipping CoreML export (not supported on Windows - requires macOS or Linux)\n",
            "Exporting to TensorFlow Lite format...\n",
            "Ultralytics 8.4.7  Python-3.12.2 torch-2.7.1+cu118 CPU (13th Gen Intel Core i7-13700F)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 47, 8400) (5.3 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['ai-edge-litert>=1.2.0'] not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting ai-edge-litert>=1.2.0\n",
            "  Downloading ai_edge_litert-2.1.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting backports.strenum (from ai-edge-litert>=1.2.0)\n",
            "  Downloading backports_strenum-1.2.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: flatbuffers in c:\\users\\labbd-2\\documents\\detection-model-training\\.venv\\lib\\site-packages (from ai-edge-litert>=1.2.0) (25.12.19)\n",
            "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\labbd-2\\documents\\detection-model-training\\.venv\\lib\\site-packages (from ai-edge-litert>=1.2.0) (2.4.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\labbd-2\\documents\\detection-model-training\\.venv\\lib\\site-packages (from ai-edge-litert>=1.2.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\labbd-2\\documents\\detection-model-training\\.venv\\lib\\site-packages (from ai-edge-litert>=1.2.0) (4.15.0)\n",
            "Requirement already satisfied: protobuf in c:\\users\\labbd-2\\documents\\detection-model-training\\.venv\\lib\\site-packages (from ai-edge-litert>=1.2.0) (6.33.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\labbd-2\\documents\\detection-model-training\\.venv\\lib\\site-packages (from tqdm->ai-edge-litert>=1.2.0) (0.4.6)\n",
            "Downloading ai_edge_litert-2.1.2-cp312-cp312-win_amd64.whl (6.1 MB)\n",
            "   ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.1/6.1 MB 975.2 kB/s eta 0:00:07\n",
            "   - -------------------------------------- 0.2/6.1 MB 1.8 MB/s eta 0:00:04\n",
            "   -- ------------------------------------- 0.3/6.1 MB 2.1 MB/s eta 0:00:03\n",
            "   --- ------------------------------------ 0.6/6.1 MB 2.7 MB/s eta 0:00:03\n",
            "   ---- ----------------------------------- 0.7/6.1 MB 3.0 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 0.7/6.1 MB 3.0 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 0.7/6.1 MB 3.0 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 0.7/6.1 MB 3.0 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 0.7/6.1 MB 1.6 MB/s eta 0:00:04\n",
            "   ---- ----------------------------------- 0.7/6.1 MB 1.6 MB/s eta 0:00:04\n",
            "   ----- ---------------------------------- 0.8/6.1 MB 1.6 MB/s eta 0:00:04\n",
            "   ------ --------------------------------- 1.1/6.1 MB 1.8 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 1.3/6.1 MB 2.0 MB/s eta 0:00:03\n",
            "   ---------- ----------------------------- 1.5/6.1 MB 2.3 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 1.7/6.1 MB 2.4 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 1.7/6.1 MB 2.4 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 1.7/6.1 MB 2.4 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 1.7/6.1 MB 2.4 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 1.7/6.1 MB 2.4 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 1.7/6.1 MB 1.8 MB/s eta 0:00:03\n",
            "   ----------- ---------------------------- 1.7/6.1 MB 1.7 MB/s eta 0:00:03\n",
            "   ----------- ---------------------------- 1.7/6.1 MB 1.7 MB/s eta 0:00:03\n",
            "   ----------- ---------------------------- 1.8/6.1 MB 1.6 MB/s eta 0:00:03\n",
            "   ------------ --------------------------- 1.9/6.1 MB 1.6 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 2.0/6.1 MB 1.7 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 2.2/6.1 MB 1.7 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 2.3/6.1 MB 1.8 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 2.4/6.1 MB 1.8 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 2.4/6.1 MB 1.8 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 2.4/6.1 MB 1.7 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 2.5/6.1 MB 1.8 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 2.7/6.1 MB 1.8 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 2.8/6.1 MB 1.8 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 3.1/6.1 MB 1.9 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 3.3/6.1 MB 2.0 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 3.5/6.1 MB 2.0 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 3.6/6.1 MB 2.1 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 3.6/6.1 MB 2.1 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 3.6/6.1 MB 2.1 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 3.6/6.1 MB 2.1 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 3.6/6.1 MB 2.1 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 3.6/6.1 MB 1.8 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 3.6/6.1 MB 1.8 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 3.6/6.1 MB 1.7 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 3.6/6.1 MB 1.7 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 3.6/6.1 MB 1.7 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 3.7/6.1 MB 1.7 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 3.8/6.1 MB 1.7 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 3.8/6.1 MB 1.6 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 3.8/6.1 MB 1.6 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 4.0/6.1 MB 1.6 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 4.1/6.1 MB 1.7 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 4.3/6.1 MB 1.7 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 4.4/6.1 MB 1.7 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 4.4/6.1 MB 1.7 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 4.4/6.1 MB 1.7 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 4.4/6.1 MB 1.7 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 4.4/6.1 MB 1.7 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 4.4/6.1 MB 1.7 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 4.5/6.1 MB 1.6 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 4.5/6.1 MB 1.6 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 4.5/6.1 MB 1.5 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 4.6/6.1 MB 1.5 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 4.6/6.1 MB 1.5 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 4.6/6.1 MB 1.5 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 4.7/6.1 MB 1.5 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 4.8/6.1 MB 1.5 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 5.0/6.1 MB 1.5 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 5.1/6.1 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 5.2/6.1 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 5.3/6.1 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 5.3/6.1 MB 1.6 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 5.3/6.1 MB 1.6 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 5.4/6.1 MB 1.5 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 5.5/6.1 MB 1.5 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 5.6/6.1 MB 1.5 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 5.7/6.1 MB 1.5 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 5.7/6.1 MB 1.5 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 5.8/6.1 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  5.9/6.1 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.0/6.1 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.1/6.1 MB 1.6 MB/s eta 0:00:00\n",
            "Downloading backports_strenum-1.2.8-py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: backports.strenum, ai-edge-litert\n",
            "Successfully installed ai-edge-litert-2.1.2 backports.strenum-1.2.8\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  15.0s\n",
            "WARNING \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.20.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.82...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.0s, saved as 'C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx' (10.2 MB)\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip': 100% ━━━━━━━━━━━━ 1.1MB 1.2MB/s 0.9s/s 0.9s<0.0s7s\n",
            "\u001b[KUnzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to C:\\Users\\labbd-2\\Documents\\detection-model-training\\calibration_image_sample_data_20x128x128x3_float32.npy...: 100% ━━━━━━━━━━━━ 1/1 111.5files/s 0.0s\n",
            "WARNING:tensorflow:From c:\\Users\\labbd-2\\Documents\\detection-model-training\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "ERROR \u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export failure 25.0s: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'\n",
            "TensorFlow Lite export failed: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'\n",
            "Note: TensorFlow Lite export has known compatibility issues on Windows.\n",
            "The ONNX format (exported above) is recommended for deployment and works on all platforms.\n",
            "\n",
            "All exports completed!\n",
            "\n",
            "Summary:\n",
            "✓ ONNX model: C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx\n",
            "Note: ONNX is the recommended format for cross-platform deployment.\n"
          ]
        }
      ],
      "source": [
        "# Export model to different formats\n",
        "export_dir = Path(\"exports\")\n",
        "export_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Check platform\n",
        "import platform\n",
        "is_windows = platform.system() == 'Windows'\n",
        "is_macos = platform.system() == 'Darwin'\n",
        "\n",
        "# Export to ONNX (recommended for deployment)\n",
        "print(\"Exporting to ONNX format...\")\n",
        "onnx_path = model.export(format='onnx', imgsz=640, optimize=True)\n",
        "print(f\"ONNX model saved at: {onnx_path}\")\n",
        "\n",
        "# Export to TensorRT (for NVIDIA GPUs)\n",
        "# Uncomment if you have TensorRT installed\n",
        "# print(\"Exporting to TensorRT format...\")\n",
        "# trt_path = model.export(format='engine', imgsz=640)\n",
        "# print(f\"TensorRT model saved at: {trt_path}\")\n",
        "\n",
        "# Export to CoreML (for Apple devices - macOS/Linux only)\n",
        "if not is_windows:\n",
        "    print(\"Exporting to CoreML format...\")\n",
        "    try:\n",
        "        coreml_path = model.export(format='coreml', imgsz=640)\n",
        "        print(f\"CoreML model saved at: {coreml_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"CoreML export failed: {e}\")\n",
        "else:\n",
        "    print(\"Skipping CoreML export (not supported on Windows - requires macOS or Linux)\")\n",
        "\n",
        "# Export to TensorFlow Lite (for mobile devices)\n",
        "# Note: TensorFlow Lite export may have compatibility issues on Windows\n",
        "# ONNX format (exported above) is recommended for cross-platform deployment\n",
        "print(\"Exporting to TensorFlow Lite format...\")\n",
        "try:\n",
        "    tflite_path = model.export(format='tflite', imgsz=640)\n",
        "    print(f\"TensorFlow Lite model saved at: {tflite_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"TensorFlow Lite export failed: {e}\")\n",
        "    print(\"Note: TensorFlow Lite export has known compatibility issues on Windows.\")\n",
        "    print(\"The ONNX format (exported above) is recommended for deployment and works on all platforms.\")\n",
        "\n",
        "print(\"\\nAll exports completed!\")\n",
        "print(\"\\nSummary:\")\n",
        "print(f\"✓ ONNX model: {onnx_path}\")\n",
        "if not is_windows:\n",
        "    print(f\"✓ CoreML model: {coreml_path if 'coreml_path' in locals() else 'Not exported'}\")\n",
        "print(\"Note: ONNX is the recommended format for cross-platform deployment.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Test the Exported Model (Optional)\n",
        "\n",
        "Test the exported ONNX model to verify it works correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing on 3 sample images...\n",
            "Loading C:\\Users\\labbd-2\\Documents\\detection-model-training\\runs\\detect\\runs\\detect\\yolo12_animal_detection\\weights\\best.onnx for ONNX Runtime inference...\n",
            "Using ONNX Runtime 1.23.2 with CUDAExecutionProvider\n",
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Error when binding input: There's no data transfer registered for copying tensors from Device:[DeviceType:1 MemoryType:0 VendorId:4318 DeviceId:0 Alignment:0] to Device:[DeviceType:0 MemoryType:0 VendorId:0 DeviceId:0 Alignment:0]",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m test_images:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTesting on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m sample images...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     results = \u001b[43monnx_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_txt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43miou\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.45\u001b[39;49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPredictions completed! Check the runs/detect directory for results.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labbd-2\\Documents\\detection-model-training\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:536\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor, \u001b[33m\"\u001b[39m\u001b[33mset_prompts\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[32m    535\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.set_prompts(prompts)\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.predict_cli(source=source) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labbd-2\\Documents\\detection-model-training\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:225\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, source, model, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs)\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labbd-2\\Documents\\detection-model-training\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m         response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     40\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labbd-2\\Documents\\detection-model-training\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:307\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;66;03m# Warmup model\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done_warmup:\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwarmup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtriton\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m     \u001b[38;5;28mself\u001b[39m.done_warmup = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;28mself\u001b[39m.seen, \u001b[38;5;28mself\u001b[39m.windows, \u001b[38;5;28mself\u001b[39m.batch = \u001b[32m0\u001b[39m, [], \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labbd-2\\Documents\\detection-model-training\\.venv\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:928\u001b[39m, in \u001b[36mAutoBackend.warmup\u001b[39m\u001b[34m(self, imgsz)\u001b[39m\n\u001b[32m    926\u001b[39m im = torch.empty(*imgsz, dtype=torch.half \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fp16 \u001b[38;5;28;01melse\u001b[39;00m torch.float, device=\u001b[38;5;28mself\u001b[39m.device)  \u001b[38;5;66;03m# input\u001b[39;00m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jit \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# warmup model\u001b[39;00m\n\u001b[32m    929\u001b[39m     warmup_boxes = torch.rand(\u001b[32m1\u001b[39m, \u001b[32m84\u001b[39m, \u001b[32m16\u001b[39m, device=\u001b[38;5;28mself\u001b[39m.device)  \u001b[38;5;66;03m# 16 boxes works best empirically\u001b[39;00m\n\u001b[32m    930\u001b[39m     warmup_boxes[:, :\u001b[32m4\u001b[39m] *= imgsz[-\u001b[32m1\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labbd-2\\Documents\\detection-model-training\\.venv\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:718\u001b[39m, in \u001b[36mAutoBackend.forward\u001b[39m\u001b[34m(self, im, augment, visualize, embed, **kwargs)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cuda:\n\u001b[32m    717\u001b[39m     im = im.cpu()\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43melement_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat16\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp16\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuffer_ptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[38;5;28mself\u001b[39m.session.run_with_iobinding(\u001b[38;5;28mself\u001b[39m.io)\n\u001b[32m    727\u001b[39m y = \u001b[38;5;28mself\u001b[39m.bindings\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labbd-2\\Documents\\detection-model-training\\.venv\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:862\u001b[39m, in \u001b[36mIOBinding.bind_input\u001b[39m\u001b[34m(self, name, device_type, device_id, element_type, shape, buffer_ptr)\u001b[39m\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, device_type, device_id, element_type, shape, buffer_ptr):\n\u001b[32m    854\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    855\u001b[39m \u001b[33;03m    :param name: input name\u001b[39;00m\n\u001b[32m    856\u001b[39m \u001b[33;03m    :param device_type: e.g. cpu, cuda, cann\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    860\u001b[39m \u001b[33;03m    :param buffer_ptr: memory pointer to input data\u001b[39;00m\n\u001b[32m    861\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iobinding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m        \u001b[49m\u001b[43mC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOrtDevice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_ort_device_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m            \u001b[49m\u001b[43mC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOrtDevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[43melement_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuffer_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: Error when binding input: There's no data transfer registered for copying tensors from Device:[DeviceType:1 MemoryType:0 VendorId:4318 DeviceId:0 Alignment:0] to Device:[DeviceType:0 MemoryType:0 VendorId:0 DeviceId:0 Alignment:0]"
          ]
        }
      ],
      "source": [
        "# Load and test the exported ONNX model\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the exported ONNX model\n",
        "onnx_model = YOLO(onnx_path)\n",
        "\n",
        "# Test on a sample image\n",
        "test_image_path = dataset_path / \"test\" / \"images\"\n",
        "if test_image_path.exists():\n",
        "    test_images = list(test_image_path.glob(\"*.jpg\"))[:3]  # Test on first 3 images\n",
        "    if test_images:\n",
        "        print(f\"Testing on {len(test_images)} sample images...\")\n",
        "        results = onnx_model.predict(\n",
        "            source=[str(img) for img in test_images],\n",
        "            save=True,\n",
        "            save_txt=True,\n",
        "            conf=0.25,\n",
        "            iou=0.45\n",
        "        )\n",
        "        print(\"Predictions completed! Check the runs/detect directory for results.\")\n",
        "    else:\n",
        "        print(\"No test images found.\")\n",
        "else:\n",
        "    print(\"Test images directory not found.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
